{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import psycopg2\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Cluster Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param       Value\n",
       "0  DWH_CLUSTER_TYPE        multi-node\n",
       "1  DWH_NUM_NODES           4         \n",
       "2  DWH_NODE_TYPE           dc2.large \n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhCluster\n",
       "4  DWH_DB                  dwh       \n",
       "5  DWH_DB_USER             dwhuser   \n",
       "6  DWH_DB_PASSWORD         Passw0rd  \n",
       "7  DWH_PORT                5439      \n",
       "8  DWH_IAM_ROLE_NAME       dwhRole   "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('clusterparams.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":[\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":[DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Redshift, S3 and IAM clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "redshift = boto3.client(\"redshift\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource(\"s3\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=config.get('AWS','KEY'),\n",
    "                    aws_secret_access_key=config.get('AWS','SECRET')\n",
    "                    )\n",
    "\n",
    "ec2 = boto3.resource(\"ec2\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new IAM Role\n"
     ]
    }
   ],
   "source": [
    "# Create the IAM role\n",
    "try:\n",
    "    print('Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "           Path='/',\n",
    "            RoleName=DWH_IAM_ROLE_NAME,\n",
    "            Description='Allow Redshift clusters to call AWS services on your behalf.',\n",
    "            AssumeRolePolicyDocument=json.dumps(\n",
    "                {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "               'Version': '2012-10-17'})\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 Attaching Policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach Policy\n",
    "print('1.2 Attaching Policy')\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                      PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\",\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Get the IAM role ARN\n"
     ]
    }
   ],
   "source": [
    "# Get the IAM role ARN\n",
    "print('1.3 Get the IAM role ARN')\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)[\"Role\"]['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING REDSHIFT CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        # hardware\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "        \n",
    "        # identifiers & credentials\n",
    "            DBName=DWH_DB,\n",
    "            ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "            MasterUsername=DWH_DB_USER,\n",
    "            MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        # parameter for role (to allow s3 access)\n",
    "         IamRoles=[roleArn]\n",
    "       \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-6fa1a417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-6fa1a417                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See cluster status\n",
    "\n",
    "def prettyRedshiftProps(props):\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Address: dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "cluster_address = myClusterProps['Endpoint']['Address']\n",
    "print('Cluster Address:', cluster_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IamRoleArn: arn:aws:iam::129357147351:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "IamRoleArn = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print('IamRoleArn:', IamRoleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening an incoming TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName= defaultSg.group_name, \n",
    "        CidrIp='0.0.0.0/0',  \n",
    "        IpProtocol='TCP',  \n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DB Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "configETL = configparser.ConfigParser()\n",
    "configETL.read_file(open('dwh.cfg'))\n",
    "LOG_DATA = configETL.get(\"S3\",\"LOG_DATA\")\n",
    "LOGPATH = configETL.get(\"S3\",\"LOG_JSONPATH\")\n",
    "SONG_DATA = configETL.get(\"S3\",\"SONG_DATA\")\n",
    "IAMROLE = configETL.get(\"IAM_ROLE\", \"ARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTING TO CLUSTER DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cursor object at 0x000001CDA5BA43C0; closed: 0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*configETL['CLUSTER'].values()))\n",
    "cur = conn.cursor()\n",
    "cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTING to S3 \"udacitiy-dend\" Bucket and Preview list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['song_data/',\n",
       " 'song_data/A/A/A/TRAAAAK128F9318786.json',\n",
       " 'song_data/A/A/A/TRAAAAV128F421A322.json',\n",
       " 'song_data/A/A/A/TRAAABD128F429CF47.json',\n",
       " 'song_data/A/A/A/TRAAACN128F9355673.json']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_data = [filename.key for filename in s3.Bucket(\"udacity-dend\").objects.filter(Prefix='song_data')]\n",
    "song_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_data/',\n",
       " 'log_data/2018/11/2018-11-01-events.json',\n",
       " 'log_data/2018/11/2018-11-02-events.json',\n",
       " 'log_data/2018/11/2018-11-03-events.json',\n",
       " 'log_data/2018/11/2018-11-04-events.json']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data = [filename.key for filename in s3.Bucket(\"udacity-dend\").objects.filter(Prefix='log_data')]\n",
    "log_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROP TABLES IF EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS staging_events\n",
      "DROP TABLE IF EXISTS staging_songs\n",
      "DROP TABLE IF EXISTS fact_songplay\n",
      "DROP TABLE IF EXISTS dim_users\n",
      "DROP TABLE IF EXISTS dim_songs\n",
      "DROP TABLE IF EXISTS dim_artists\n",
      "DROP TABLE IF EXISTS dim_time\n"
     ]
    }
   ],
   "source": [
    "drop_staging_events = \"DROP TABLE IF EXISTS staging_events\"\n",
    "drop_staging_songs = \"DROP TABLE IF EXISTS staging_songs\"\n",
    "drop_fact_songplay = \"DROP TABLE IF EXISTS fact_songplay\"\n",
    "drop_dim_users = \"DROP TABLE IF EXISTS dim_users\"\n",
    "drop_dim_songs = \"DROP TABLE IF EXISTS dim_songs\"\n",
    "drop_dim_artists = \"DROP TABLE IF EXISTS dim_artists\"\n",
    "drop_dim_time = \"DROP TABLE IF EXISTS dim_time\"\n",
    "\n",
    "tables_to_drop = [drop_staging_events,drop_staging_songs,drop_fact_songplay, \n",
    "                  drop_dim_users, drop_dim_songs,drop_dim_artists,drop_dim_time]\n",
    "\n",
    "for table in tables_to_drop:\n",
    "    cur.execute(table)\n",
    "    conn.commit()\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESIGNING STAGING, FACT & DIMENSION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGING tables are used to stage before modeling into Star Schema\n",
    "\n",
    "create_staging_events = (\"\"\"CREATE TABLE IF NOT EXISTS staging_events(\n",
    "artist VARCHAR,\n",
    "auth VARCHAR,\n",
    "firstName VARCHAR,\n",
    "gender VARCHAR,\n",
    "itemInSession INTEGER,\n",
    "lastName VARCHAR,\n",
    "length FLOAT,\n",
    "level VARCHAR,\n",
    "location VARCHAR,\n",
    "method VARCHAR,\n",
    "page VARCHAR,\n",
    "registration BIGINT,\n",
    "sessionId INTEGER,\n",
    "song VARCHAR,\n",
    "status INTEGER,\n",
    "ts TIMESTAMP,\n",
    "userAgent VARCHAR,\n",
    "userId INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "create_staging_songs = (\"\"\"CREATE TABLE IF NOT EXISTS staging_songs(\n",
    "num_songs VARCHAR,\n",
    "artist_id VARCHAR, \n",
    "artist_latitude FLOAT, \n",
    "artist_longitude FLOAT, \n",
    "artist_location VARCHAR, \n",
    "artist_name VARCHAR, \n",
    "song_id VARCHAR, \n",
    "title VARCHAR, \n",
    "duration FLOAT,\n",
    "year INT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "create_fact_songplay = (\"\"\"CREATE TABLE IF NOT EXISTS fact_songplay\n",
    "(\n",
    "songplay_id INTEGER IDENTITY(0,1) PRIMARY KEY sortkey,\n",
    "start_time TIMESTAMP,\n",
    "user_id INTEGER, \n",
    "level VARCHAR, \n",
    "song_id VARCHAR,\n",
    "artist_id VARCHAR,\n",
    "session_id INTEGER,\n",
    "location VARCHAR,\n",
    "user_agent VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_users = (\"\"\"CREATE TABLE IF NOT EXISTS dim_users\n",
    "(\n",
    "user_id INTEGER PRIMARY KEY distkey,\n",
    "first_name VARCHAR,\n",
    "last_name VARCHAR,\n",
    "gender VARCHAR,\n",
    "level VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_songs = (\"\"\"CREATE TABLE IF NOT EXISTS dim_songs\n",
    "(\n",
    "song_id VARCHAR PRIMARY KEY,\n",
    "title VARCHAR, \n",
    "artist_id VARCHAR distkey,\n",
    "year INTEGER, \n",
    "duration FLOAT)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_artists = (\"\"\"CREATE TABLE IF NOT EXISTS dim_artists\n",
    "(\n",
    "artist_id VARCHAR PRIMARY KEY distkey,\n",
    "name VARCHAR, \n",
    "location VARCHAR, \n",
    "lattitude FLOAT, \n",
    "longitude FLOAT)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_time = (\"\"\"CREATE TABLE IF NOT EXISTS dim_time\n",
    "(\n",
    "start_time TIMESTAMP PRIMARY KEY sortkey distkey, \n",
    "hour INTEGER, \n",
    "day INTEGER, \n",
    "week INTEGER, \n",
    "month INTEGER, \n",
    "year INTEGER, \n",
    "weekday INTEGER)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING STAGING, FACT & DIMENSION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n"
     ]
    }
   ],
   "source": [
    "tables_to_create =[create_staging_events, create_staging_songs, create_fact_songplay, create_dim_users, create_dim_songs,\n",
    "                   create_dim_artists, create_dim_time]\n",
    "\n",
    "for table in tables_to_create:\n",
    "    cur.execute(table)\n",
    "    print(\"Table created\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPY staging_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging events copied\n"
     ]
    }
   ],
   "source": [
    "copy_staging_events = (\"\"\"\n",
    "COPY staging_events FROM {}\n",
    "CREDENTIALS 'aws_iam_role={}'\n",
    "COMPUPDATE OFF region 'us-west-2'\n",
    "TIMEFORMAT as 'epochmillisecs'\n",
    "TRUNCATECOLUMNS BLANKSASNULL EMPTYASNULL\n",
    "FORMAT AS JSON {};\n",
    "\"\"\").format(LOG_DATA, IAMROLE, LOGPATH)\n",
    "\n",
    "cur.execute(copy_staging_events)\n",
    "print(\"staging events copied\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A Fine Frenzy', 'Logged In', 'Anabelle', 'F', 0, 'Simpson', 267.91138, 'free', 'Philadelphia-Camden-Wilmington, PA-NJ-DE-MD', 'PUT', 'NextSong', 1541044398796, 256, 'Almost Lover (Album Version)', 200, datetime.datetime(2018, 11, 5, 0, 33, 12, 796000), '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"', 69)\n",
      "\n",
      "('Nirvana', 'Logged In', 'Aleena', 'F', 0, 'Kirby', 214.77832, 'paid', 'Waterloo-Cedar Falls, IA', 'PUT', 'NextSong', 1541022995796, 237, 'Serve The Servants', 200, datetime.datetime(2018, 11, 5, 1, 27, 22, 796000), 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0', 44)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW staging_events\n",
    "##  artist, auth, firstName, gender, itemInSession, lastName, length, level, location, method, page, registration, sessionId, song, status, ts, userAgent, userId\n",
    "\n",
    "query = cur.execute(\"\"\"SELECT * FROM staging_events\"\"\")\n",
    "for i in range(2):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COPY staging_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging songs copied\n"
     ]
    }
   ],
   "source": [
    "copy_staging_songs = (\"\"\"\n",
    "COPY staging_songs FROM {}\n",
    "CREDENTIALS 'aws_iam_role={}'\n",
    "COMPUPDATE OFF region 'us-west-2'\n",
    "FORMAT AS JSON 'auto'\n",
    "TRUNCATECOLUMNS BLANKSASNULL EMPTYASNULL\n",
    "\"\"\").format(SONG_DATA, IAMROLE)\n",
    "\n",
    "cur.execute(copy_staging_songs)\n",
    "print(\"staging songs copied\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 'ARXQBR11187B98A2CC', None, None, 'Liverpool, England', 'Frankie Goes To Hollywood', 'SOBRKGM12A8C139EF6', 'Welcome to the Pleasuredome', 821.05424, 1985)\n",
      "('1', 'AR62OVB1187FB48D09', None, None, None, 'H.O.S.H.', 'SOTUITZ12AB0181A80', 'Ben Johnson', 431.96036, 0)\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW staging_songs\n",
    "## num_songs, artist_id,  artist_latitude ,  artist_longitude ,  artist_location,  artist_name,  song_id,  title,  duration, year\n",
    "\n",
    "query = cur.execute(\"\"\"SELECT * FROM staging_songs\"\"\")\n",
    "for i in range(2):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO FACT_songplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 11, 15, 21, 11, 36, 796000), 44, 'paid', 'SOCNCGL127D9786D66', 'AREHK7O1187B9ADDD7', 619, 'Waterloo-Cedar Falls, IA', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "\n",
      "(datetime.datetime(2018, 11, 7, 7, 58, 28, 796000), 100, 'free', 'SODTPBM12A8C1339D7', 'AR4OH581187B9B7157', 301, 'New York-Newark-Jersey City, NY-NJ-PA', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW QUERY B4 INSERTING\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT e.ts,\n",
    "                e.userId as user_id,\n",
    "                e.level as level,\n",
    "                s.song_id as song_id,\n",
    "                s.artist_id as artist_id,\n",
    "                e.sessionId as session_id,\n",
    "                e.location as location,\n",
    "                e.userAgent as user_agent\n",
    "FROM staging_events e\n",
    "JOIN staging_songs s ON e.song = s.title AND e.artist = s.artist_name\n",
    "WHERE e.page='NextSong'\n",
    "\"\"\")\n",
    "\n",
    "for i in range(2):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, datetime.datetime(2018, 11, 20, 17, 46, 38, 796000), 49, 'paid', 'SOCHRXB12A8AE48069', 'ARTDQRC1187FB4EFD4', 758, 'San Francisco-Oakland-Hayward, CA', 'Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "\n",
      "(15, datetime.datetime(2018, 11, 6, 16, 38, 15, 796000), 2, 'free', 'SOSMXVH12A58A7CA6C', 'AR6PJ8R1187FB5AD70', 126, 'Plymouth, IN', '\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"')\n",
      "\n",
      "(22, datetime.datetime(2018, 11, 18, 20, 48, 21, 796000), 29, 'paid', 'SOWGZFG12A8151AF41', 'ARC8CQZ1187B98DECA', 589, 'Atlanta-Sandy Springs-Roswell, GA', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO fact_songplay (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "                                    SELECT DISTINCT e.ts,\n",
    "                                                    e.userId as user_id,\n",
    "                                                    e.level as level,\n",
    "                                                    s.song_id as song_id,\n",
    "                                                    s.artist_id as artist_id,\n",
    "                                                    e.sessionId as session_id,\n",
    "                                                    e.location as location,\n",
    "                                                    e.userAgent as user_agent\n",
    "                                    FROM staging_events e\n",
    "                                    JOIN staging_songs s ON e.song = s.title AND e.artist = s.artist_name\n",
    "                                    WHERE e.page='NextSong'\n",
    "                                  \"\"\")\n",
    "\n",
    "# Preview newly created fact_songplay table\n",
    "query = cur.execute(\"\"\"SELECT * FROM fact_songplay\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO dim_users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 'Anabelle', 'Simpson', 'F', 'free')\n",
      "\n",
      "(44, 'Aleena', 'Kirby', 'F', 'paid')\n",
      "\n",
      "(52, 'Theodore', 'Smith', 'M', 'free')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW QUERY B4 INSERTING\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT userId as user_id,\n",
    "                firstName as first_name,\n",
    "                lastName as last_name,\n",
    "                gender as gender,\n",
    "                level as level\n",
    "FROM staging_events\n",
    "where userId IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 'Jahiem', 'Miles', 'M', 'free')\n",
      "\n",
      "(26, 'Ryan', 'Smith', 'M', 'free')\n",
      "\n",
      "(12, 'Austin', 'Rosales', 'M', 'free')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_users(user_id, first_name, last_name, gender, level)\n",
    "                        SELECT DISTINCT userId as user_id,\n",
    "                                        firstName as first_name,\n",
    "                                        lastName as last_name,\n",
    "                                        gender as gender,\n",
    "                                        level as level\n",
    "                        FROM staging_events\n",
    "                        where userId IS NOT NULL;\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Preview newly created dim_users table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_users\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO dim_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SOCOKEW12A8C136D13', 'Labyrinth', 'AR8Y6HV1187FB5546D', 2008, 352.67873)\n",
      "('SOVISQQ12AB0184B6D', 'Sina Mory', 'AR3ZGUC1187FB57721', 2010, 267.59791)\n",
      "('SOKBBXV12AB0186B8A', 'Papel Quemado', 'ARMIQRB12298900AFB', 0, 309.96853)\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW query b4 inserting\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "                    FROM staging_songs\n",
    "                    WHERE song_id IS NOT NULL\n",
    "                    \"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SOBBRKE12AB0181388', 'Tricky Woman', 'AR6NJ1P1187FB59DAB', 1995, 215.11791)\n",
      "\n",
      "('SOMJJJT12AB0182379', 'Foolish Silence', 'ARISGWX119B8669508', 0, 276.89751)\n",
      "\n",
      "('SONCPQC12A58A7D3A7', 'Spark', 'ARWHM281187FB3D381', 2002, 220.96934)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_songs (song_id, title, artist_id, year, duration)\n",
    "                SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "                FROM staging_songs\n",
    "                WHERE song_id IS NOT NULL\n",
    "                \"\"\")\n",
    "\n",
    "\n",
    "# Preview newly created dim_users table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_songs\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERTING INTO dim_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AR6C8EJ1187FB3F473', 'Nelson Ned', ' Ubá, Minas Gerais', None, None)\n",
      "('ARUB0K61187B9B9AC3', 'Hot Water Music', 'Gainesville, FL', 29.65195, -82.32318)\n",
      "('ARSL5SP1187B9A7AE0', 'N.W.A.', 'Compton, California, USA.', 34.05349, -118.24532)\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW query b4 inserting\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT artist_id, e.artist as name, s.artist_location, s.artist_latitude, s.artist_longitude\n",
    "                        FROM staging_events e\n",
    "                        JOIN staging_songs s ON e.artist = s.artist_name\n",
    "                        WHERE e.artist IS NOT NULL\n",
    "                    \"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ARB60IV1187FB370FE', 'Reverend Horton Heat', 'Corpus Christi, TX', 32.77815, -96.7954)\n",
      "\n",
      "('AR1ZYLH1187B98C159', 'Naughty By Nature', 'East Orange, NJ', None, None)\n",
      "\n",
      "('AR5J8XN1187B9B712E', 'Extreme', None, None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_artists(artist_id, name, location, lattitude, longitude)\n",
    "                   SELECT DISTINCT artist_id, e.artist as name, s.artist_location, s.artist_latitude, s.artist_longitude\n",
    "                   FROM staging_events e\n",
    "                   JOIN staging_songs s ON e.artist = s.artist_name\n",
    "                   WHERE e.artist IS NOT NULL\n",
    "            \"\"\")\n",
    "\n",
    "# Preview newly created dim_artist table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_artists\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERTING INTO dim_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2018, 11, 5, 0, 33, 12, 796000), 0, 5, 45, 11, 2018, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview query to insert\n",
    "cur.execute(\"\"\"SELECT DISTINCT ts, \n",
    "               extract(h from ts) AS hour, \n",
    "               extract(d from ts) AS day, \n",
    "               extract(w from ts) AS week, \n",
    "               extract(mon from ts) AS month, \n",
    "               extract(year from ts) AS year, \n",
    "               extract(dow from ts) AS weekday\n",
    "               FROM staging_events WHERE ts IS NOT NULL\n",
    "\"\"\")\n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 11, 1, 21, 52, 5, 796000), 21, 1, 44, 11, 2018, 4)\n",
      "\n",
      "(datetime.datetime(2018, 11, 1, 22, 23, 14, 796000), 22, 1, 44, 11, 2018, 4)\n",
      "\n",
      "(datetime.datetime(2018, 11, 2, 2, 42, 48, 796000), 2, 2, 44, 11, 2018, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_time(start_time, hour, day, week, month, year, weekday)\n",
    "               SELECT DISTINCT ts, \n",
    "               extract(h from ts) AS hour, \n",
    "               extract(d from ts) AS day, \n",
    "               extract(w from ts) AS week, \n",
    "               extract(mon from ts) AS month, \n",
    "               extract(year from ts) AS year, \n",
    "               extract(dow from ts) AS weekday\n",
    "               FROM staging_events WHERE ts IS NOT NULL\n",
    "            \"\"\")\n",
    "\n",
    "# Preview newly created dim_time table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_time\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "2018-11-09 19:35:24.796000\n",
      "36\n",
      "paid\n",
      "SOBJUKG12A58A7DCA8\n",
      "AR9W3X91187FB3994C\n",
      "392\n",
      "Janesville-Beloit, WI\n",
      "\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"\n",
      "36\n",
      "Matthew\n",
      "Jones\n",
      "M\n",
      "paid\n",
      "AR9W3X91187FB3994C\n",
      "Phil Collins\n",
      "Chiswick, London, England\n",
      "None\n",
      "None\n",
      "SOBJUKG12A58A7DCA8\n",
      "Two Hearts\n",
      "AR9W3X91187FB3994C\n",
      "1988\n",
      "204.19873\n",
      "2018-11-09 19:35:24.796000\n",
      "19\n",
      "9\n",
      "45\n",
      "11\n",
      "2018\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182</td>\n",
       "      <td>2018-11-09 19:35:24.796</td>\n",
       "      <td>36</td>\n",
       "      <td>paid</td>\n",
       "      <td>SOBJUKG12A58A7DCA8</td>\n",
       "      <td>AR9W3X91187FB3994C</td>\n",
       "      <td>392</td>\n",
       "      <td>Janesville-Beloit, WI</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>AR9W3X91187FB3994C</td>\n",
       "      <td>1988</td>\n",
       "      <td>204.19873</td>\n",
       "      <td>2018-11-09 19:35:24.796</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0                       1   2     3                   4  \\\n",
       "0  182 2018-11-09 19:35:24.796  36  paid  SOBJUKG12A58A7DCA8   \n",
       "\n",
       "                    5    6                      7  \\\n",
       "0  AR9W3X91187FB3994C  392  Janesville-Beloit, WI   \n",
       "\n",
       "                                                                                                          8  \\\n",
       "0  \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"   \n",
       "\n",
       "    9  ...                  21    22         23                      24  25  \\\n",
       "0  36  ...  AR9W3X91187FB3994C  1988  204.19873 2018-11-09 19:35:24.796  19   \n",
       "\n",
       "  26  27  28    29 30  \n",
       "0  9  45  11  2018  5  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join each dim table to the fact table and preview it\n",
    "\n",
    "cur.execute(\"\"\"SELECT * FROM fact_songplay fs\n",
    "JOIN dim_users on fs.user_id = dim_users.user_id\n",
    "JOIN dim_artists on fs.artist_id = dim_artists.artist_id\n",
    "JOIN dim_songs on fs.song_id = dim_songs.song_id\n",
    "JOIN dim_time on fs.start_time = dim_time.start_time\n",
    "\"\"\")\n",
    "df = pd.DataFrame(cur.fetchone()).T\n",
    "\n",
    "\n",
    "for value in list(df.values[0]):\n",
    "    print(value)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete your cluster and resources after no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2021, 7, 30, 13, 57, 36, 686000, tzinfo=tzutc()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-d4539de2',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-6fa1a417',\n",
       "  'AvailabilityZone': 'us-west-2d',\n",
       "  'PreferredMaintenanceWindow': 'sun:07:30-sun:08:00',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::129357147351:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2021, 8, 1, 7, 30, tzinfo=tzutc()),\n",
       "  'TotalStorageCapacityInMegaBytes': 1600000,\n",
       "  'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "   'AquaConfigurationStatus': 'auto'}},\n",
       " 'ResponseMetadata': {'RequestId': 'a625a2a6-e3ec-4fee-a7a5-6407db166c87',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a625a2a6-e3ec-4fee-a7a5-6407db166c87',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2622',\n",
       "   'vary': 'accept-encoding',\n",
       "   'date': 'Fri, 30 Jul 2021 16:42:13 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete Cluster\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-6fa1a417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  deleting                                                                               \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-6fa1a417                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check deletion status\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '06950b7a-69b9-421f-b225-29f425e4c7c1',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '06950b7a-69b9-421f-b225-29f425e4c7c1',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '200',\n",
       "   'date': 'Fri, 30 Jul 2021 16:42:16 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detach role policy & DELETE role\n",
    "iam.detach_role_policy(RoleName=DWH_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DWH_IAM_ROLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
