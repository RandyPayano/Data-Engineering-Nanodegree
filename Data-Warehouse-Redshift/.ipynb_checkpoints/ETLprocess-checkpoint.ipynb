{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import psycopg2\n",
    "import configparser\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Cluster Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DWH_CLUSTER_TYPE</td>\n",
       "      <td>multi-node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DWH_NUM_NODES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DWH_NODE_TYPE</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DWH_CLUSTER_IDENTIFIER</td>\n",
       "      <td>dwhCluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DWH_DB</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DWH_DB_USER</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DWH_DB_PASSWORD</td>\n",
       "      <td>Passw0rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DWH_PORT</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DWH_IAM_ROLE_NAME</td>\n",
       "      <td>dwhRole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Param       Value\n",
       "0        DWH_CLUSTER_TYPE  multi-node\n",
       "1           DWH_NUM_NODES           4\n",
       "2           DWH_NODE_TYPE   dc2.large\n",
       "3  DWH_CLUSTER_IDENTIFIER  dwhCluster\n",
       "4                  DWH_DB         dwh\n",
       "5             DWH_DB_USER     dwhuser\n",
       "6         DWH_DB_PASSWORD    Passw0rd\n",
       "7                DWH_PORT        5439\n",
       "8       DWH_IAM_ROLE_NAME     dwhRole"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('clusterparams.cfg'))\n",
    "\n",
    "KEY                    = config.get('AWS','KEY')\n",
    "SECRET                 = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE       = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES          = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE          = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB                 = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER            = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD        = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT               = config.get(\"DWH\",\"DWH_PORT\")\n",
    "\n",
    "DWH_IAM_ROLE_NAME      = config.get(\"DWH\", \"DWH_IAM_ROLE_NAME\")\n",
    "\n",
    "(DWH_DB_USER, DWH_DB_PASSWORD, DWH_DB)\n",
    "\n",
    "pd.DataFrame({\"Param\":[\"DWH_CLUSTER_TYPE\", \"DWH_NUM_NODES\", \"DWH_NODE_TYPE\", \"DWH_CLUSTER_IDENTIFIER\", \"DWH_DB\", \"DWH_DB_USER\", \"DWH_DB_PASSWORD\", \"DWH_PORT\", \"DWH_IAM_ROLE_NAME\"],\n",
    "              \"Value\":[DWH_CLUSTER_TYPE, DWH_NUM_NODES, DWH_NODE_TYPE, DWH_CLUSTER_IDENTIFIER, DWH_DB, DWH_DB_USER, DWH_DB_PASSWORD, DWH_PORT, DWH_IAM_ROLE_NAME]\n",
    "             })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Redshift, S3 and IAM clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "iam_resource = boto3.resource(\"iam\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "redshift = boto3.client(\"redshift\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "s3 = boto3.resource(\"s3\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=config.get('AWS','KEY'),\n",
    "                    aws_secret_access_key=config.get('AWS','SECRET')\n",
    "                    )\n",
    "\n",
    "ec2 = boto3.resource(\"ec2\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an IAM Role that makes Redshift able to access S3 bucket (ReadOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new IAM Role\n"
     ]
    }
   ],
   "source": [
    "# Create the IAM role\n",
    "try:\n",
    "    print('Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "           Path='/',\n",
    "            RoleName=\"dwhRole\",\n",
    "            Description='Allow Redshift clusters to call AWS services on your behalf.',\n",
    "            AssumeRolePolicyDocument=json.dumps(\n",
    "                {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "               'Version': '2012-10-17'})\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 Attaching Policy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach Policy\n",
    "print('1.2 Attaching Policy')\n",
    "\n",
    "iam.attach_role_policy(RoleName=DWH_IAM_ROLE_NAME,\n",
    "                      PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\",\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 Get the IAM role ARN\n"
     ]
    }
   ],
   "source": [
    "# Get the IAM role ARN\n",
    "print('1.3 Get the IAM role ARN')\n",
    "roleArn = iam.get_role(RoleName=DWH_IAM_ROLE_NAME)[\"Role\"]['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING REDSHIFT CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        # hardware\n",
    "        ClusterType=DWH_CLUSTER_TYPE,\n",
    "        NodeType=DWH_NODE_TYPE,\n",
    "        NumberOfNodes=int(DWH_NUM_NODES),\n",
    "        \n",
    "        # identifiers & credentials\n",
    "            DBName=DWH_DB,\n",
    "            ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,\n",
    "            MasterUsername=DWH_DB_USER,\n",
    "            MasterUserPassword=DWH_DB_PASSWORD,\n",
    "        \n",
    "        # parameter for role (to allow s3 access)\n",
    "         IamRoles=[roleArn]\n",
    "       \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c2hvwovgwksn.us-west-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-6fa1a417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key                                              Value\n",
       "0  ClusterIdentifier                                         dwhcluster\n",
       "1           NodeType                                          dc2.large\n",
       "2      ClusterStatus                                          available\n",
       "3     MasterUsername                                            dwhuser\n",
       "4             DBName                                                dwh\n",
       "5           Endpoint  {'Address': 'dwhcluster.c2hvwovgwksn.us-west-2...\n",
       "6              VpcId                                       vpc-6fa1a417\n",
       "7      NumberOfNodes                                                  4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See cluster status\n",
    "\n",
    "def prettyRedshiftProps(props):\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]['Endpoint']['Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vpc-6fa1a417'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_VpcId(props):\n",
    "    keysToShow = ['VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "vpcid = get_VpcId(myClusterProps)['Value'][0]\n",
    "vpcid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_address = myClusterProps['Endpoint']['Address']\n",
    "print('Cluster Address:', cluster_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IamRoleArn = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print('IamRoleArn:', IamRoleArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening an incoming TCP port to access the cluster ednpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec2.SecurityGroup(id='sg-d4539de2')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "list(vpc.security_groups.all())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-090660dff8f84df61')\n",
      "ec2.SecurityGroup(id='sg-090660dff8f84df61')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    " \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName= defaultSg.group_name, \n",
    "        CidrIp='0.0.0.0/0',  \n",
    "        IpProtocol='TCP',  \n",
    "        FromPort=int(DWH_PORT),\n",
    "        ToPort=int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter Filters[0].Values, value: haha, type: <class 'str'>, valid types: <class 'list'>, <class 'tuple'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-b66ceab54341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     )\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mec2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe_security_groups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFilters\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"group-name\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Values\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"haha\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[1;34m'auth_type'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         }\n\u001b[1;32m--> 677\u001b[1;33m         request_dict = self._convert_to_request_dict(\n\u001b[0m\u001b[0;32m    678\u001b[0m             api_params, operation_model, context=request_context)\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[1;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[0;32m    723\u001b[0m         api_params = self._emit_api_params(\n\u001b[0;32m    724\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m--> 725\u001b[1;33m         request_dict = self._serializer.serialize_to_request(\n\u001b[0m\u001b[0;32m    726\u001b[0m             api_params, operation_model)\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[1;34m(self, parameters, operation_model)\u001b[0m\n\u001b[0;32m    317\u001b[0m                                                     operation_model.input_shape)\n\u001b[0;32m    318\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[0;32m    321\u001b[0m                                                      operation_model)\n",
      "\u001b[1;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter Filters[0].Values, value: haha, type: <class 'str'>, valid types: <class 'list'>, <class 'tuple'>"
     ]
    }
   ],
   "source": [
    "ec2 = boto3.client(\"ec2\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "ec2.describe_security_groups(Filters= [{\"Name\": \"group-name\", \"Values\": \"haha\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ec2.SecurityGroup(id='sg-d4539de2')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vpc.security_groups.all())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SecurityGroups': [{'Description': 'Redshift security group',\n",
       "   'GroupName': 'SG_Name',\n",
       "   'IpPermissions': [{'FromPort': 5439,\n",
       "     'IpProtocol': 'tcp',\n",
       "     'IpRanges': [{'CidrIp': '0.0.0.0/0'}],\n",
       "     'Ipv6Ranges': [],\n",
       "     'PrefixListIds': [],\n",
       "     'ToPort': 5439,\n",
       "     'UserIdGroupPairs': []}],\n",
       "   'OwnerId': '129357147351',\n",
       "   'GroupId': 'sg-090660dff8f84df61',\n",
       "   'IpPermissionsEgress': [{'IpProtocol': '-1',\n",
       "     'IpRanges': [{'CidrIp': '0.0.0.0/0'}],\n",
       "     'Ipv6Ranges': [],\n",
       "     'PrefixListIds': [],\n",
       "     'UserIdGroupPairs': []}],\n",
       "   'VpcId': 'vpc-6fa1a417'}],\n",
       " 'ResponseMetadata': {'RequestId': '9e640499-f2a5-46c7-871c-441bf79ece9b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '9e640499-f2a5-46c7-871c-441bf79ece9b',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '1519',\n",
       "   'date': 'Wed, 04 Aug 2021 17:14:24 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsecname = 'secbamid1'\n",
    "\n",
    "ec2.describe_security_groups(Filters= [{\"Name\": \"group-name\", \"Values\":['SG_Name']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClusterNotFoundFault",
     "evalue": "An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClusterNotFoundFault\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-ef9eddb3596e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Key\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmyClusterProps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mredshift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mClusterIdentifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDWH_CLUSTER_IDENTIFIER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Clusters'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mvpcid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_VpcId\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyClusterProps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Code\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mClusterNotFoundFault\u001b[0m: An error occurred (ClusterNotFound) when calling the DescribeClusters operation: Cluster dwhcluster not found."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "ec2 = boto3.client(\"ec2\",\n",
    "                    region_name=\"us-west-2\",\n",
    "                    aws_access_key_id=KEY,\n",
    "                    aws_secret_access_key=SECRET\n",
    "                    )\n",
    "\n",
    "\n",
    "def get_VpcId(props):\n",
    "    keysToShow = ['VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "vpcid = get_VpcId(myClusterProps)['Value'][0]\n",
    "\n",
    "\n",
    "\n",
    "def Create_Security_Group(Groupid):\n",
    "    ec2 = boto3.client(\"ec2\",\n",
    "                        region_name=\"us-west-2\",\n",
    "                        aws_access_key_id=KEY,\n",
    "                        aws_secret_access_key=SECRET\n",
    "                        )\n",
    "\n",
    "    try: \n",
    "        response = ec2.describe_security_groups(Filters= [{\"Name\": \"group-name\", \"Values\": [Groupid]}])\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "    if len(response['SecurityGroups']) > 0:\n",
    "        print('Security Group already exists: ' + response['SecurityGroups'][0]['GroupId'])\n",
    "        return response['SecurityGroups'][0]['GroupId']\n",
    "    \n",
    "    else:\n",
    "        response = None\n",
    "        \n",
    "    \n",
    "    if response is None:\n",
    "        # Assuming the security goroup doesn't exist, go ahead and create it\n",
    "        try:\n",
    "            ###### Make sure security group name is in config\n",
    "            response = ec2.create_security_group(GroupName= Groupid,\n",
    "                                                 Description='Redshift security group',\n",
    "                                                 VpcId=get_VpcId(myClusterProps)['Value'][0])\n",
    "           \n",
    "            security_group_id = response['GroupId']\n",
    "            print(\"Security Group created\")\n",
    "            print(security_group_id, get_VpcId(myClusterProps)['Value'][0])\n",
    "        \n",
    "            ec2.authorize_security_group_ingress(\n",
    "            GroupId=str(security_group_id),\n",
    "            CidrIp='0.0.0.0/0',  \n",
    "            IpProtocol='TCP',  \n",
    "            FromPort=int(DWH_PORT),\n",
    "            ToPort=int(DWH_PORT)\n",
    "        )\n",
    "            return security_group_id\n",
    "        except Exception as e:\n",
    "            print(e)            \n",
    "\n",
    "            \n",
    "            \n",
    "Create_Security_Group('sg_badconnect2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SecurityGroups': [],\n",
       " 'ResponseMetadata': {'RequestId': 'd346cfa6-c50c-42fe-856d-06d5323d0fd9',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd346cfa6-c50c-42fe-856d-06d5323d0fd9',\n",
       "   'cache-control': 'no-cache, no-store',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'content-type': 'text/xml;charset=UTF-8',\n",
       "   'content-length': '243',\n",
       "   'date': 'Wed, 04 Aug 2021 17:12:30 GMT',\n",
       "   'server': 'AmazonEC2'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec2.describe_security_groups(Filters= [{\"Name\": \"group-name\", \"Values\": ['HAHAHA']}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_security_group():\n",
    "  \n",
    "    try:\n",
    "        response = ec2.describe_security_groups(GroupIds=['sg-d4539de2'])\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "\n",
    "  if len(response['SecurityGroups']) > 0:\n",
    "    print('Security Group already exists: ' + response['SecurityGroups'][0]['GroupId'])\n",
    "    return response['SecurityGroups'][0]['GroupId']\n",
    "  else:\n",
    "    response = None\n",
    "\n",
    "  if response is None:\n",
    "    vpc_id = config.get('SECURITY', 'VPC_ID')\n",
    "    if vpc_id == \"\":\n",
    "      response = ec2_client.describe_vpcs()\n",
    "      vpc_id = response.get('Vpcs', [{}])[0].get('VpcId', '')\n",
    "\n",
    "    try:\n",
    "        response = ec2_client.create_security_group(GroupName=config.get('SECURITY', 'SG_Name'),Description='Redshift security group',VpcId=vpc_id)\n",
    "        security_group_id = response['GroupId']\n",
    "        print('Security Group Created %s in vpc %s.' % (security_group_id, vpc_id))\n",
    "\n",
    "        ec2_client.authorize_security_group_ingress(\n",
    "            GroupId=security_group_id,\n",
    "            IpPermissions=[\n",
    "                {'IpProtocol': 'tcp',\n",
    "                 'FromPort': 80,\n",
    "                 'ToPort': 80,\n",
    "                 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]},\n",
    "                {'IpProtocol': 'tcp',\n",
    "                 'FromPort': 5439,\n",
    "                 'ToPort': 5439,\n",
    "                 'IpRanges': [{'CidrIp': '0.0.0.0/0'}]}\n",
    "            ])\n",
    "        return security_group_id\n",
    "    except ClientError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading DB Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "configETL = configparser.ConfigParser()\n",
    "configETL.read_file(open('func.cfg'))\n",
    "LOG_DATA = configETL.get(\"S3\",\"log_data\")\n",
    "LOGPATH = configETL.get(\"S3\",\"log_jsonpath\")\n",
    "SONG_DATA = configETL.get(\"S3\",\"song_data\")\n",
    "IAMROLE = configETL.get(\"AWS\", \"rolearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTING TO CLUSTER DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cursor object at 0x000001A866C0A820; closed: 0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*configETL['CLUSTER'].values()))\n",
    "cur = conn.cursor()\n",
    "cur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTING to S3 \"udacitiy-dend\" Bucket and Preview list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = [filename.key for filename in s3.Bucket(\"udacity-dend\").objects.filter(Prefix='song_data')]\n",
    "song_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = [filename.key for filename in s3.Bucket(\"udacity-dend\").objects.filter(Prefix='log_data')]\n",
    "log_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROP TABLES IF EXISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROP TABLE IF EXISTS staging_events\n",
      "DROP TABLE IF EXISTS staging_songs\n",
      "DROP TABLE IF EXISTS fact_songplay\n",
      "DROP TABLE IF EXISTS dim_users\n",
      "DROP TABLE IF EXISTS dim_songs\n",
      "DROP TABLE IF EXISTS dim_artists\n",
      "DROP TABLE IF EXISTS dim_time\n"
     ]
    }
   ],
   "source": [
    "drop_staging_events = \"DROP TABLE IF EXISTS staging_events\"\n",
    "drop_staging_songs = \"DROP TABLE IF EXISTS staging_songs\"\n",
    "drop_fact_songplay = \"DROP TABLE IF EXISTS fact_songplay\"\n",
    "drop_dim_users = \"DROP TABLE IF EXISTS dim_users\"\n",
    "drop_dim_songs = \"DROP TABLE IF EXISTS dim_songs\"\n",
    "drop_dim_artists = \"DROP TABLE IF EXISTS dim_artists\"\n",
    "drop_dim_time = \"DROP TABLE IF EXISTS dim_time\"\n",
    "\n",
    "tables_to_drop = [drop_staging_events,drop_staging_songs,drop_fact_songplay, \n",
    "                  drop_dim_users, drop_dim_songs,drop_dim_artists,drop_dim_time]\n",
    "\n",
    "for table in tables_to_drop:\n",
    "    cur.execute(table)\n",
    "    conn.commit()\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESIGNING STAGING, FACT & DIMENSION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGING tables are used to stage before modeling into Star Schema\n",
    "\n",
    "create_staging_events = (\"\"\"CREATE TABLE IF NOT EXISTS staging_events(\n",
    "artist VARCHAR,\n",
    "auth VARCHAR,\n",
    "firstName VARCHAR,\n",
    "gender VARCHAR,\n",
    "itemInSession INTEGER,\n",
    "lastName VARCHAR,\n",
    "length FLOAT,\n",
    "level VARCHAR,\n",
    "location VARCHAR,\n",
    "method VARCHAR,\n",
    "page VARCHAR,\n",
    "registration BIGINT,\n",
    "sessionId INTEGER,\n",
    "song VARCHAR,\n",
    "status INTEGER,\n",
    "ts TIMESTAMP,\n",
    "userAgent VARCHAR,\n",
    "userId INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "create_staging_songs = (\"\"\"CREATE TABLE IF NOT EXISTS staging_songs(\n",
    "num_songs VARCHAR,\n",
    "artist_id VARCHAR, \n",
    "artist_latitude FLOAT, \n",
    "artist_longitude FLOAT, \n",
    "artist_location VARCHAR, \n",
    "artist_name VARCHAR, \n",
    "song_id VARCHAR, \n",
    "title VARCHAR, \n",
    "duration FLOAT,\n",
    "year INT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "create_fact_songplay = (\"\"\"CREATE TABLE IF NOT EXISTS fact_songplay\n",
    "(\n",
    "songplay_id INTEGER IDENTITY(0,1) PRIMARY KEY sortkey,\n",
    "start_time TIMESTAMP,\n",
    "user_id INTEGER, \n",
    "level VARCHAR, \n",
    "song_id VARCHAR,\n",
    "artist_id VARCHAR,\n",
    "session_id INTEGER,\n",
    "location VARCHAR,\n",
    "user_agent VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_users = (\"\"\"CREATE TABLE IF NOT EXISTS dim_users\n",
    "(\n",
    "user_id INTEGER PRIMARY KEY distkey,\n",
    "first_name VARCHAR,\n",
    "last_name VARCHAR,\n",
    "gender VARCHAR,\n",
    "level VARCHAR)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_songs = (\"\"\"CREATE TABLE IF NOT EXISTS dim_songs\n",
    "(\n",
    "song_id VARCHAR PRIMARY KEY,\n",
    "title VARCHAR, \n",
    "artist_id VARCHAR distkey,\n",
    "year INTEGER, \n",
    "duration FLOAT)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_artists = (\"\"\"CREATE TABLE IF NOT EXISTS dim_artists\n",
    "(\n",
    "artist_id VARCHAR PRIMARY KEY distkey,\n",
    "name VARCHAR, \n",
    "location VARCHAR, \n",
    "lattitude FLOAT, \n",
    "longitude FLOAT)\n",
    "\"\"\")\n",
    "\n",
    "create_dim_time = (\"\"\"CREATE TABLE IF NOT EXISTS dim_time\n",
    "(\n",
    "start_time TIMESTAMP PRIMARY KEY sortkey distkey, \n",
    "hour INTEGER, \n",
    "day INTEGER, \n",
    "week INTEGER, \n",
    "month INTEGER, \n",
    "year INTEGER, \n",
    "weekday INTEGER)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING STAGING, FACT & DIMENSION TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n",
      "Table created\n"
     ]
    }
   ],
   "source": [
    "tables_to_create =[create_staging_events, create_staging_songs, create_fact_songplay, create_dim_users, create_dim_songs,\n",
    "                   create_dim_artists, create_dim_time]\n",
    "\n",
    "for table in tables_to_create:\n",
    "    cur.execute(table)\n",
    "    print(\"Table created\")\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPY staging_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging events copied\n"
     ]
    }
   ],
   "source": [
    "copy_staging_events = (\"\"\"\n",
    "COPY staging_events FROM {}\n",
    "CREDENTIALS 'aws_iam_role={}'\n",
    "COMPUPDATE OFF region 'us-west-2'\n",
    "TIMEFORMAT as 'epochmillisecs'\n",
    "TRUNCATECOLUMNS BLANKSASNULL EMPTYASNULL\n",
    "FORMAT AS JSON {};\n",
    "\"\"\").format(LOG_DATA, IAMROLE, LOGPATH)\n",
    "\n",
    "cur.execute(copy_staging_events)\n",
    "print(\"staging events copied\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 'Logged In', 'Adler', 'M', 0, 'Barrera', None, 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'GET', 'Home', 1540835983796, 248, None, 200, datetime.datetime(2018, 11, 6, 2, 12, 44, 796000), '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"', 100)\n",
      "\n",
      "('Gustavo Cerati', 'Logged In', 'Adler', 'M', 1, 'Barrera', 249.44281, 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'PUT', 'NextSong', 1540835983796, 248, 'Uno Entre 1000', 200, datetime.datetime(2018, 11, 6, 2, 13, 3, 796000), '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"', 100)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW staging_events\n",
    "##  artist, auth, firstName, gender, itemInSession, lastName, length, level, location, method, page, registration, sessionId, song, status, ts, userAgent, userId\n",
    "\n",
    "query = cur.execute(\"\"\"SELECT * FROM staging_events\"\"\")\n",
    "for i in range(2):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COPY staging_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging songs copied\n"
     ]
    }
   ],
   "source": [
    "copy_staging_songs = (\"\"\"\n",
    "COPY staging_songs FROM {}\n",
    "CREDENTIALS 'aws_iam_role={}'\n",
    "COMPUPDATE OFF region 'us-west-2'\n",
    "FORMAT AS JSON 'auto'\n",
    "TRUNCATECOLUMNS BLANKSASNULL EMPTYASNULL\n",
    "\"\"\").format(SONG_DATA, IAMROLE)\n",
    "\n",
    "cur.execute(copy_staging_songs)\n",
    "print(\"staging songs copied\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 'ARZ5H0P1187B98A1DD', 33.76672, -118.1924, 'Long Beach, CA', 'Snoop Dogg', 'SOAPERH12A58A787DC', 'The One And Only (Edited)', 230.42567, 0)\n",
      "('1', 'ARNQAVF11F4C844C04', None, None, None, 'Despina Vandi', 'SOVXMTN12A8C135A18', 'OUTE ENA EFHARISTO', 303.09832, 0)\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW staging_songs\n",
    "## num_songs, artist_id,  artist_latitude ,  artist_longitude ,  artist_location,  artist_name,  song_id,  title,  duration, year\n",
    "\n",
    "query = cur.execute(\"\"\"SELECT * FROM staging_songs\"\"\")\n",
    "for i in range(2):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO FACT_songplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 11, 30, 4, 57, 3, 796000), 49, 'paid', 'SOEMXXF12A6D4F932C', 'ARI4S0E1187B9B06C0', 1079, 'San Francisco-Oakland-Hayward, CA', 'Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "\n",
      "(datetime.datetime(2018, 11, 20, 1, 24, 48, 796000), 25, 'paid', 'SOULTKQ12AB018A183', 'ARKQQZA12086C116FC', 594, 'Marinette, WI-MI', '\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW QUERY B4 INSERTING\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT e.ts,\n",
    "                e.userId as user_id,\n",
    "                e.level as level,\n",
    "                s.song_id as song_id,\n",
    "                s.artist_id as artist_id,\n",
    "                e.sessionId as session_id,\n",
    "                e.location as location,\n",
    "                e.userAgent as user_agent\n",
    "FROM staging_events e\n",
    "JOIN staging_songs s ON e.song = s.title AND e.artist = s.artist_name\n",
    "WHERE e.page='NextSong'\n",
    "\"\"\")\n",
    "\n",
    "for i in range(2):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, datetime.datetime(2018, 11, 27, 18, 22, 58, 796000), 36, 'paid', 'SODFRAX12A8C13274B', 'ARP29T31187B98DD5F', 957, 'Janesville-Beloit, WI', '\"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"')\n",
      "\n",
      "(15, datetime.datetime(2018, 11, 13, 20, 20, 44, 796000), 29, 'paid', 'SOKUAEP12A8C13BE19', 'ARLLWJQ1187B9B06A7', 556, 'Atlanta-Sandy Springs-Roswell, GA', '\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.78.2 (KHTML, like Gecko) Version/7.0.6 Safari/537.78.2\"')\n",
      "\n",
      "(22, datetime.datetime(2018, 11, 24, 15, 47, 42, 796000), 49, 'paid', 'SOCGOZK12A8151BD5D', 'ARM0P6Z1187FB4D466', 849, 'San Francisco-Oakland-Hayward, CA', 'Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO fact_songplay (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent)\n",
    "                                    SELECT DISTINCT e.ts,\n",
    "                                                    e.userId as user_id,\n",
    "                                                    e.level as level,\n",
    "                                                    s.song_id as song_id,\n",
    "                                                    s.artist_id as artist_id,\n",
    "                                                    e.sessionId as session_id,\n",
    "                                                    e.location as location,\n",
    "                                                    e.userAgent as user_agent\n",
    "                                    FROM staging_events e\n",
    "                                    JOIN staging_songs s ON e.song = s.title AND e.artist = s.artist_name\n",
    "                                    WHERE e.page='NextSong'\n",
    "                                  \"\"\")\n",
    "\n",
    "# Preview newly created fact_songplay table\n",
    "query = cur.execute(\"\"\"SELECT * FROM fact_songplay\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO dim_users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 'Adler', 'Barrera', 'M', 'free')\n",
      "\n",
      "(61, 'Samuel', 'Gonzalez', 'M', 'free')\n",
      "\n",
      "(55, 'Martin', 'Johnson', 'M', 'free')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW QUERY B4 INSERTING\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT userId as user_id,\n",
    "                firstName as first_name,\n",
    "                lastName as last_name,\n",
    "                gender as gender,\n",
    "                level as level\n",
    "FROM staging_events\n",
    "where userId IS NOT NULL;\n",
    "\"\"\")\n",
    "\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 'Ryan', 'Smith', 'M', 'free')\n",
      "\n",
      "(12, 'Austin', 'Rosales', 'M', 'free')\n",
      "\n",
      "(17, 'Makinley', 'Jones', 'F', 'free')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_users(user_id, first_name, last_name, gender, level)\n",
    "                        SELECT DISTINCT userId as user_id,\n",
    "                                        firstName as first_name,\n",
    "                                        lastName as last_name,\n",
    "                                        gender as gender,\n",
    "                                        level as level\n",
    "                        FROM staging_events\n",
    "                        where userId IS NOT NULL;\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Preview newly created dim_users table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_users\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT INTO dim_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SODZURJ12A6D4F938C', \"In God's Name (Album Version)\", 'ARHK7VE1187B994E06', 2003, 308.45342)\n",
      "('SOSGQQS12A8C137AF5', 'Mile High', 'AROYNG01187FB56BA9', 1987, 239.85587)\n",
      "('SOMPEQV12AF72A616A', 'Nixon', 'AREMPER1187B9AEB42', 2005, 189.962)\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW query b4 inserting\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "                    FROM staging_songs\n",
    "                    WHERE song_id IS NOT NULL\n",
    "                    \"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SOUIZBU12A8C1458F8', 'By The Way', 'AR70CDT1187FB5796F', 1970, 181.57669)\n",
      "\n",
      "('SOVDXIY12A8C142D40', 'Your Mantra', 'ARYVVLF1241B9CC03B', 0, 159.84281)\n",
      "\n",
      "('SOAUGJA12AB01869AF', 'The Ambush', 'ARV2X851187FB41A78', 2004, 136.98567)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_songs (song_id, title, artist_id, year, duration)\n",
    "                SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "                FROM staging_songs\n",
    "                WHERE song_id IS NOT NULL\n",
    "                \"\"\")\n",
    "\n",
    "\n",
    "# Preview newly created dim_users table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_songs\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERTING INTO dim_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ARN0GFV1187FB508CC', 'Wiz Khalifa', None, None, None)\n",
      "('AR9GUZF1187FB4D1BC', '10_000 Maniacs', 'Jamestown, NY', None, None)\n",
      "('ARR6LWJ1187FB44C8B', 'R.E.M.', 'Athens, GA', None, None)\n"
     ]
    }
   ],
   "source": [
    "# PREVIEW query b4 inserting\n",
    "query = cur.execute(\"\"\"SELECT DISTINCT artist_id, e.artist as name, s.artist_location, s.artist_latitude, s.artist_longitude\n",
    "                        FROM staging_events e\n",
    "                        JOIN staging_songs s ON e.artist = s.artist_name\n",
    "                        WHERE e.artist IS NOT NULL\n",
    "                    \"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ARQT8QM1187FB3E3CB', 'The Bats', 'Christchurch, New Zealand', -43.53131, 172.6373)\n",
      "\n",
      "('ARVWNTI1269FB34C59', 'SOJA', None, None, None)\n",
      "\n",
      "('ARDGES11187B9B7DDF', 'Roxy Music', 'Newcastle', None, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_artists(artist_id, name, location, lattitude, longitude)\n",
    "                   SELECT DISTINCT artist_id, e.artist as name, s.artist_location, s.artist_latitude, s.artist_longitude\n",
    "                   FROM staging_events e\n",
    "                   JOIN staging_songs s ON e.artist = s.artist_name\n",
    "                   WHERE e.artist IS NOT NULL\n",
    "            \"\"\")\n",
    "\n",
    "# Preview newly created dim_artist table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_artists\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERTING INTO dim_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2018, 11, 6, 2, 12, 44, 796000), 2, 6, 45, 11, 2018, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview query to insert\n",
    "cur.execute(\"\"\"SELECT DISTINCT ts, \n",
    "               extract(h from ts) AS hour, \n",
    "               extract(d from ts) AS day, \n",
    "               extract(w from ts) AS week, \n",
    "               extract(mon from ts) AS month, \n",
    "               extract(year from ts) AS year, \n",
    "               extract(dow from ts) AS weekday\n",
    "               FROM staging_events WHERE ts IS NOT NULL\n",
    "\"\"\")\n",
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(datetime.datetime(2018, 11, 1, 21, 1, 46, 796000), 21, 1, 44, 11, 2018, 4)\n",
      "\n",
      "(datetime.datetime(2018, 11, 1, 21, 5, 52, 796000), 21, 1, 44, 11, 2018, 4)\n",
      "\n",
      "(datetime.datetime(2018, 11, 2, 9, 1, 21, 796000), 9, 2, 44, 11, 2018, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"INSERT INTO dim_time(start_time, hour, day, week, month, year, weekday)\n",
    "               SELECT DISTINCT ts, \n",
    "               extract(h from ts) AS hour, \n",
    "               extract(d from ts) AS day, \n",
    "               extract(w from ts) AS week, \n",
    "               extract(mon from ts) AS month, \n",
    "               extract(year from ts) AS year, \n",
    "               extract(dow from ts) AS weekday\n",
    "               FROM staging_events WHERE ts IS NOT NULL\n",
    "            \"\"\")\n",
    "\n",
    "# Preview newly created dim_time table \n",
    "query = cur.execute(\"\"\"SELECT * FROM dim_time\"\"\")\n",
    "for i in range(3):\n",
    "        row = cur.fetchone()\n",
    "        if row == None:\n",
    "            break\n",
    "        print(row)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fetchall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d6894c9f6537>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresoverall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresoverall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fetchall'"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(resoverall.fetchall())\n",
    "df.columns = resoverall.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"You're The One\", 37), (\"I CAN'T GET STARTED\", 9), ('Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', 9), (\"Nothin' On You [feat. Bruno Mars] (Album Version)\", 8), (\"Hey Daddy (Daddy's Home)\", 6)]\n"
     ]
    }
   ],
   "source": [
    "# List the top 5 songs according to plays amount\n",
    "cur.execute(\"\"\"select dim_songs.title, count(dim_songs.title) as count_plays from dim_songs join fact_songplay on dim_songs.song_id = fact_songplay.song_id Group By dim_songs.title Order By count_plays Desc LIMIT 5\"\"\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# dim artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dwight Yoakam', 37), ('Kid Cudi / Kanye West / Common', 10), ('Kid Cudi', 10), ('Ron Carter', 9), ('Lonnie Gordon', 9)]\n"
     ]
    }
   ],
   "source": [
    "# Rank top 5 artist according to play amount\n",
    "cur.execute(\"\"\"select da.name as artist_name, Count(name) As plays from fact_songplay as fsp inner join dim_artists as da on fsp.artist_id = da.artist_id Group By name Order By Plays Desc Limit 5\"\"\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('New York-Newark-Jersey City, NY-NJ-PA', 4), ('Houston-The Woodlands-Sugar Land, TX', 3), ('Atlanta-Sandy Springs-Roswell, GA', 3), ('Columbia, SC', 2), ('Philadelphia-Camden-Wilmington, PA-NJ-DE-MD', 2)]\n"
     ]
    }
   ],
   "source": [
    "# List top 5 locations by distint users amount\n",
    "\n",
    "cur.execute(\"\"\"select fs.location, count(distinct(users.user_id)) as count from dim_users as users join fact_songplay as fs on users.user_id = fs.user_id Group By fs.location ORDER BY count Desc LIMIT 5\"\"\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(17, 40), (18, 26), (15, 25), (16, 24), (8, 18)]\n"
     ]
    }
   ],
   "source": [
    "# List top 5 hours by play amount\n",
    "# List top 5 locations by distint users amount\n",
    "# Rank top 5 artist according to play amount\n",
    "# List the top 5 songs according to plays amount\n",
    "cur.execute(\"\"\"select t.hour, Count(1) As Plays from fact_songplay as sp inner join dim_time as t on sp.start_time = t.start_time Group By t.hour Order By Plays Desc LIMIT 5\"\"\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325</td>\n",
       "      <td>2018-11-29 08:23:09.796</td>\n",
       "      <td>98</td>\n",
       "      <td>free</td>\n",
       "      <td>SOYJPKO12A6D4FDCEA</td>\n",
       "      <td>ARC3KQN1187FB54018</td>\n",
       "      <td>865</td>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>98</td>\n",
       "      <td>Jordyn</td>\n",
       "      <td>Powell</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "      <td>ARC3KQN1187FB54018</td>\n",
       "      <td>School Of Seven Bells</td>\n",
       "      <td>Brooklyn NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOYJPKO12A6D4FDCEA</td>\n",
       "      <td>s.Ada.Licht</td>\n",
       "      <td>ARC3KQN1187FB54018</td>\n",
       "      <td>2007</td>\n",
       "      <td>176.97914</td>\n",
       "      <td>2018-11-29 08:23:09.796</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152</td>\n",
       "      <td>2018-11-04 06:51:12.796</td>\n",
       "      <td>25</td>\n",
       "      <td>paid</td>\n",
       "      <td>SORKKTY12A8C132F3E</td>\n",
       "      <td>ARIH5GU1187FB4C958</td>\n",
       "      <td>128</td>\n",
       "      <td>Marinette, WI-MI</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...</td>\n",
       "      <td>25</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>Graves</td>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>ARIH5GU1187FB4C958</td>\n",
       "      <td>Silverchair</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SORKKTY12A8C132F3E</td>\n",
       "      <td>The Door</td>\n",
       "      <td>ARIH5GU1187FB4C958</td>\n",
       "      <td>1997</td>\n",
       "      <td>213.13261</td>\n",
       "      <td>2018-11-04 06:51:12.796</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-11-15 21:25:45.796</td>\n",
       "      <td>49</td>\n",
       "      <td>paid</td>\n",
       "      <td>SOKHAAU12A6D4F71EF</td>\n",
       "      <td>ARDD09D1187B99AD60</td>\n",
       "      <td>630</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "      <td>Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...</td>\n",
       "      <td>49</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>Cuevas</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "      <td>ARDD09D1187B99AD60</td>\n",
       "      <td>Lindisfarne</td>\n",
       "      <td>OLIVEHILL</td>\n",
       "      <td>35.27374</td>\n",
       "      <td>-88.03295</td>\n",
       "      <td>SOKHAAU12A6D4F71EF</td>\n",
       "      <td>Fog On The Tyne (Live)</td>\n",
       "      <td>ARDD09D1187B99AD60</td>\n",
       "      <td>0</td>\n",
       "      <td>352.39138</td>\n",
       "      <td>2018-11-15 21:25:45.796</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272</td>\n",
       "      <td>2018-11-02 18:36:53.796</td>\n",
       "      <td>71</td>\n",
       "      <td>free</td>\n",
       "      <td>SOBBZPM12AB017DF4B</td>\n",
       "      <td>ARH6W4X1187B99274F</td>\n",
       "      <td>70</td>\n",
       "      <td>Columbia, SC</td>\n",
       "      <td>\"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_1 like...</td>\n",
       "      <td>71</td>\n",
       "      <td>Ayleen</td>\n",
       "      <td>Wise</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "      <td>ARH6W4X1187B99274F</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>Oxford, UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOBBZPM12AB017DF4B</td>\n",
       "      <td>Pop Is Dead</td>\n",
       "      <td>ARH6W4X1187B99274F</td>\n",
       "      <td>1993</td>\n",
       "      <td>130.82077</td>\n",
       "      <td>2018-11-02 18:36:53.796</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>2018-11-13 17:47:05.796</td>\n",
       "      <td>29</td>\n",
       "      <td>paid</td>\n",
       "      <td>SOJWFXM12A3F1EBE8B</td>\n",
       "      <td>AR049S81187B9AE8A5</td>\n",
       "      <td>486</td>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>29</td>\n",
       "      <td>Jacqueline</td>\n",
       "      <td>Lynch</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "      <td>AR049S81187B9AE8A5</td>\n",
       "      <td>The Human League</td>\n",
       "      <td>Sheffield, Yorkshire, England</td>\n",
       "      <td>53.38311</td>\n",
       "      <td>-1.46454</td>\n",
       "      <td>SOJWFXM12A3F1EBE8B</td>\n",
       "      <td>Human</td>\n",
       "      <td>AR049S81187B9AE8A5</td>\n",
       "      <td>1986</td>\n",
       "      <td>265.35138</td>\n",
       "      <td>2018-11-13 17:47:05.796</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0                       1   2     3                   4   \\\n",
       "0  325 2018-11-29 08:23:09.796  98  free  SOYJPKO12A6D4FDCEA   \n",
       "1  152 2018-11-04 06:51:12.796  25  paid  SORKKTY12A8C132F3E   \n",
       "2   11 2018-11-15 21:25:45.796  49  paid  SOKHAAU12A6D4F71EF   \n",
       "3  272 2018-11-02 18:36:53.796  71  free  SOBBZPM12AB017DF4B   \n",
       "4  228 2018-11-13 17:47:05.796  29  paid  SOJWFXM12A3F1EBE8B   \n",
       "\n",
       "                   5    6                                            7   \\\n",
       "0  ARC3KQN1187FB54018  865  Philadelphia-Camden-Wilmington, PA-NJ-DE-MD   \n",
       "1  ARIH5GU1187FB4C958  128                             Marinette, WI-MI   \n",
       "2  ARDD09D1187B99AD60  630            San Francisco-Oakland-Hayward, CA   \n",
       "3  ARH6W4X1187B99274F   70                                 Columbia, SC   \n",
       "4  AR049S81187B9AE8A5  486            Atlanta-Sandy Springs-Roswell, GA   \n",
       "\n",
       "                                                  8   9           10      11  \\\n",
       "0  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  98      Jordyn  Powell   \n",
       "1  \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...  25      Jayden  Graves   \n",
       "2  Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20...  49       Chloe  Cuevas   \n",
       "3  \"Mozilla/5.0 (iPhone; CPU iPhone OS 7_1_1 like...  71      Ayleen    Wise   \n",
       "4  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...  29  Jacqueline   Lynch   \n",
       "\n",
       "  12    13                  14                     15  \\\n",
       "0  F  free  ARC3KQN1187FB54018  School Of Seven Bells   \n",
       "1  M  paid  ARIH5GU1187FB4C958            Silverchair   \n",
       "2  F  paid  ARDD09D1187B99AD60            Lindisfarne   \n",
       "3  F  free  ARH6W4X1187B99274F              Radiohead   \n",
       "4  F  paid  AR049S81187B9AE8A5       The Human League   \n",
       "\n",
       "                              16        17        18                  19  \\\n",
       "0                    Brooklyn NY       NaN       NaN  SOYJPKO12A6D4FDCEA   \n",
       "1                      Newcastle       NaN       NaN  SORKKTY12A8C132F3E   \n",
       "2                      OLIVEHILL  35.27374 -88.03295  SOKHAAU12A6D4F71EF   \n",
       "3                     Oxford, UK       NaN       NaN  SOBBZPM12AB017DF4B   \n",
       "4  Sheffield, Yorkshire, England  53.38311  -1.46454  SOJWFXM12A3F1EBE8B   \n",
       "\n",
       "                       20                  21    22         23  \\\n",
       "0             s.Ada.Licht  ARC3KQN1187FB54018  2007  176.97914   \n",
       "1                The Door  ARIH5GU1187FB4C958  1997  213.13261   \n",
       "2  Fog On The Tyne (Live)  ARDD09D1187B99AD60     0  352.39138   \n",
       "3             Pop Is Dead  ARH6W4X1187B99274F  1993  130.82077   \n",
       "4                   Human  AR049S81187B9AE8A5  1986  265.35138   \n",
       "\n",
       "                       24  25  26  27  28    29  30  \n",
       "0 2018-11-29 08:23:09.796   8  29  48  11  2018   4  \n",
       "1 2018-11-04 06:51:12.796   6   4  44  11  2018   0  \n",
       "2 2018-11-15 21:25:45.796  21  15  46  11  2018   4  \n",
       "3 2018-11-02 18:36:53.796  18   2  44  11  2018   5  \n",
       "4 2018-11-13 17:47:05.796  17  13  46  11  2018   2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join each dim table to the fact table and preview it\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "cur.execute(\"\"\"SELECT * FROM fact_songplay fs\n",
    "JOIN dim_users on fs.user_id = dim_users.user_id\n",
    "JOIN dim_artists on fs.artist_id = dim_artists.artist_id\n",
    "JOIN dim_songs on fs.song_id = dim_songs.song_id\n",
    "JOIN dim_time on fs.start_time = dim_time.start_time\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "pd.DataFrame(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete your cluster and resources after no longer needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cluster': {'ClusterIdentifier': 'dwhcluster',\n",
       "  'NodeType': 'dc2.large',\n",
       "  'ClusterStatus': 'deleting',\n",
       "  'ClusterAvailabilityStatus': 'Modifying',\n",
       "  'MasterUsername': 'dwhuser',\n",
       "  'DBName': 'dwh',\n",
       "  'Endpoint': {'Address': 'dwhcluster.c2hvwovgwksn.us-west-2.redshift.amazonaws.com',\n",
       "   'Port': 5439},\n",
       "  'ClusterCreateTime': datetime.datetime(2021, 8, 11, 16, 19, 24, 705000, tzinfo=tzutc()),\n",
       "  'AutomatedSnapshotRetentionPeriod': 1,\n",
       "  'ManualSnapshotRetentionPeriod': -1,\n",
       "  'ClusterSecurityGroups': [],\n",
       "  'VpcSecurityGroups': [{'VpcSecurityGroupId': 'sg-d4539de2',\n",
       "    'Status': 'active'}],\n",
       "  'ClusterParameterGroups': [{'ParameterGroupName': 'default.redshift-1.0',\n",
       "    'ParameterApplyStatus': 'in-sync'}],\n",
       "  'ClusterSubnetGroupName': 'default',\n",
       "  'VpcId': 'vpc-6fa1a417',\n",
       "  'AvailabilityZone': 'us-west-2c',\n",
       "  'PreferredMaintenanceWindow': 'sat:07:00-sat:07:30',\n",
       "  'PendingModifiedValues': {},\n",
       "  'ClusterVersion': '1.0',\n",
       "  'AllowVersionUpgrade': True,\n",
       "  'NumberOfNodes': 4,\n",
       "  'PubliclyAccessible': True,\n",
       "  'Encrypted': False,\n",
       "  'Tags': [],\n",
       "  'EnhancedVpcRouting': False,\n",
       "  'IamRoles': [{'IamRoleArn': 'arn:aws:iam::129357147351:role/dwhRole',\n",
       "    'ApplyStatus': 'in-sync'}],\n",
       "  'MaintenanceTrackName': 'current',\n",
       "  'DeferredMaintenanceWindows': [],\n",
       "  'NextMaintenanceWindowStartTime': datetime.datetime(2021, 8, 14, 7, 0, tzinfo=tzutc()),\n",
       "  'TotalStorageCapacityInMegaBytes': 1600000,\n",
       "  'AquaConfiguration': {'AquaStatus': 'disabled',\n",
       "   'AquaConfigurationStatus': 'auto'}},\n",
       " 'ResponseMetadata': {'RequestId': '3c3ad5dc-c961-4f94-b3de-80954269e2a2',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '3c3ad5dc-c961-4f94-b3de-80954269e2a2',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '2622',\n",
       "   'vary': 'accept-encoding',\n",
       "   'date': 'Wed, 11 Aug 2021 16:31:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete Cluster\n",
    "redshift.delete_cluster( ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>deleting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c2hvwovgwksn.us-west-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-6fa1a417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key                                              Value\n",
       "0  ClusterIdentifier                                         dwhcluster\n",
       "1           NodeType                                          dc2.large\n",
       "2      ClusterStatus                                           deleting\n",
       "3     MasterUsername                                            dwhuser\n",
       "4             DBName                                                dwh\n",
       "5           Endpoint  {'Address': 'dwhcluster.c2hvwovgwksn.us-west-2...\n",
       "6              VpcId                                       vpc-6fa1a417\n",
       "7      NumberOfNodes                                                  4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check deletion status\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchEntityException",
     "evalue": "An error occurred (NoSuchEntity) when calling the DetachRolePolicy operation: The role with name dwhRole cannot be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchEntityException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-2c0ceb44f52b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Detach role policy & DELETE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0miam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_role_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRoleName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dwhRole\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPolicyArn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'arn:aws:iam::aws:policy/ReadOnlyAccess'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0miam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete_role\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRoleName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dwhRole\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Code\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchEntityException\u001b[0m: An error occurred (NoSuchEntity) when calling the DetachRolePolicy operation: The role with name dwhRole cannot be found."
     ]
    }
   ],
   "source": [
    "# Detach role policy & DELETE \n",
    "iam.detach_role_policy(RoleName=\"dwhRole\", PolicyArn='arn:aws:iam::aws:policy/ReadOnlyAccess')\n",
    "iam.delete_role(RoleName=\"dwhRole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nMissing required parameter in input: \"PolicyArn\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-f0cd36d503bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_role_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRoleName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dwhRole\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[1;34m'auth_type'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moperation_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         }\n\u001b[1;32m--> 677\u001b[1;33m         request_dict = self._convert_to_request_dict(\n\u001b[0m\u001b[0;32m    678\u001b[0m             api_params, operation_model, context=request_context)\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[1;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[0;32m    723\u001b[0m         api_params = self._emit_api_params(\n\u001b[0;32m    724\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m--> 725\u001b[1;33m         request_dict = self._serializer.serialize_to_request(\n\u001b[0m\u001b[0;32m    726\u001b[0m             api_params, operation_model)\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\botocore\\validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[1;34m(self, parameters, operation_model)\u001b[0m\n\u001b[0;32m    317\u001b[0m                                                     operation_model.input_shape)\n\u001b[0;32m    318\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[0;32m    321\u001b[0m                                                      operation_model)\n",
      "\u001b[1;31mParamValidationError\u001b[0m: Parameter validation failed:\nMissing required parameter in input: \"PolicyArn\""
     ]
    }
   ],
   "source": [
    " iam.detach_role_policy(RoleName=\"dwhRole\", PolicyArn=Policy_Arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To validate ETL, please choose from one of the following queries: \n",
      "\n",
      "1) Rank top 5 locations according to users amount\n",
      "2) Rank top 5 artist according to play amount\n",
      "3) Rank top 5 songs according to plays amount\n",
      "4) Rank top 5 hours according to play amount\n",
      "\n",
      " Which question would you like to answer? (Enter a number from 1-4): 2\n",
      "\n",
      "select da.name as artist_name, Count(name) As plays from fact_songplay as fsp inner join dim_artists as \n",
      "                    da on fsp.artist_id = da.artist_id Group By name Order By Plays Desc Limit 5\n"
     ]
    }
   ],
   "source": [
    "print(\"To validate ETL, please choose from one of the following queries: \\n\")\n",
    "\n",
    "\n",
    "print(\"1) Rank top 5 locations according to users amount\")\n",
    "print(\"2) Rank top 5 artist according to play amount\")\n",
    "print(\"3) Rank top 5 songs according to play amount\")\n",
    "print(\"4) Rank top 5 hours according to play amount\")\n",
    "\n",
    "query_num = input(\"\\n Which question would you like to answer? (Enter a number from 1-4): \")\n",
    "\n",
    "queries = {\"1\": \"\"\"select fs.location, count(distinct(users.user_id)) as count from dim_users as users join fact_songplay as \n",
    "                   fs on users.user_id = fs.user_id Group By fs.location ORDER BY count Desc LIMIT 5\"\"\",\n",
    "           \n",
    "           \"2\": \"\"\"select da.name as artist_name, Count(name) As plays from fact_songplay as fsp inner join dim_artists as \n",
    "                    da on fsp.artist_id = da.artist_id Group By name Order By Plays Desc Limit 5\"\"\",\n",
    "    \n",
    "           \"3\": \"\"\"select dim_songs.title, count(dim_songs.title) as count_plays from dim_songs join fact_songplay on dim_songs.song_id = \n",
    "                   fact_songplay.song_id Group By dim_songs.title Order By count_plays Desc LIMIT 5\"\"\",\n",
    "           \n",
    "           \"4\": \"\"\"select t.hour, Count(1) As Plays from fact_songplay as sp inner join dim_time as t on \n",
    "                   sp.start_time = t.start_time Group By t.hour Order By Plays Desc LIMIT 5\"\"\"\n",
    "          }\n",
    "print(\"\")\n",
    "\n",
    "print(queries[query_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List top 5 hours by play amount\n",
    "# List top 5 locations by distint users amount\n",
    "# Rank top 5 artist according to play amount\n",
    "# List the top 5 songs according to plays amount"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
